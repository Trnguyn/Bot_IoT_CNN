{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d75978bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7845137e",
   "metadata": {},
   "source": [
    "## 1. Load All CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8d9d6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số file: 75\n"
     ]
    }
   ],
   "source": [
    "# Đường dẫn data\n",
    "data_path = Path(r'c:\\Users\\Tplab\\OneDrive\\CNN tutorial\\data\\raw')\n",
    "csv_files = sorted(list(data_path.glob('*.csv')))\n",
    "\n",
    "print(f\"Tổng số file: {len(csv_files)}\")\n",
    "\n",
    "# Tên cột\n",
    "column_names = [\n",
    "    'pkSeqID', 'stime', 'flgs', 'proto', 'saddr', 'sport', 'daddr', 'dport',\n",
    "    'pkts', 'bytes', 'state', 'ltime', 'seq', 'dur', 'mean', 'stddev',\n",
    "    'smac', 'dmac', 'sum', 'min', 'max', 'soui', 'doui', 'sco', 'dco',\n",
    "    'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'srate', 'drate',\n",
    "    'attack', 'category', 'subcategory'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f1e24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 20 files đầu tiên (để tránh tràn RAM)\n",
    "# Có thể tăng lên sau khi test xong\n",
    "NUM_FILES = 20\n",
    "\n",
    "print(f\"Đang merge {NUM_FILES} files đầu tiên...\")\n",
    "df_list = []\n",
    "\n",
    "for i, file in enumerate(csv_files[:NUM_FILES], 1):\n",
    "    df_temp = pd.read_csv(file, header=None, names=column_names, low_memory=False)\n",
    "    df_list.append(df_temp)\n",
    "    print(f\"Đã load {i}/{NUM_FILES} files...\")\n",
    "    \n",
    "    # Giải phóng memory ngay sau khi append\n",
    "    del df_temp\n",
    "\n",
    "# Concat all dataframes\n",
    "print(\"\\nĐang concat dataframes...\")\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Giải phóng df_list\n",
    "del df_list\n",
    "\n",
    "print(f\"\\nMerge hoàn tất!\")\n",
    "print(f\"Total shape: {df.shape}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab267c95",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885abca4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Xóa các cột hoàn toàn rỗng\u001b[39;00m\n\u001b[0;32m      2\u001b[0m columns_to_drop \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmac\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdmac\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoui\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoui\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msco\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdco\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mcolumns_to_drop)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mĐã xóa \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns_to_drop)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cột rỗng\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape sau khi xóa: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Xóa các cột hoàn toàn rỗng\n",
    "columns_to_drop = ['smac', 'dmac', 'soui', 'doui', 'sco', 'dco']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "print(f\"Đã xóa {len(columns_to_drop)} cột rỗng\")\n",
    "print(f\"Shape sau khi xóa: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882a6346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra duplicates\n",
    "print(f\"Số dòng trùng lặp: {df.duplicated().sum():,}\")\n",
    "\n",
    "# Xóa duplicates\n",
    "df = df.drop_duplicates()\n",
    "print(f\"Shape sau khi xóa duplicates: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e50637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values trong sport và dport\n",
    "print(\"Missing values trước khi xử lý:\")\n",
    "print(df[['sport', 'dport']].isnull().sum())\n",
    "\n",
    "# Fill missing với giá trị đặc biệt (0 hoặc 'unknown')\n",
    "df['sport'] = df['sport'].fillna('0')\n",
    "df['dport'] = df['dport'].fillna('0')\n",
    "\n",
    "print(\"\\nMissing values sau khi xử lý:\")\n",
    "print(df[['sport', 'dport']].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0426bf",
   "metadata": {},
   "source": [
    "## 3. Analyze Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb36dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phân bố attack/normal\n",
    "print(\"Attack distribution:\")\n",
    "print(df['attack'].value_counts())\n",
    "print(f\"\\nAttack ratio: {df['attack'].value_counts(normalize=True)*100}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Category distribution:\")\n",
    "print(df['category'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Subcategory distribution:\")\n",
    "print(df['subcategory'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a1af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Attack\n",
    "df['attack'].value_counts().plot(kind='bar', ax=axes[0])\n",
    "axes[0].set_title('Attack Distribution (0=Normal, 1=Attack)')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Category\n",
    "df['category'].value_counts().plot(kind='bar', ax=axes[1])\n",
    "axes[1].set_title('Category Distribution')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Subcategory (top 10)\n",
    "df['subcategory'].value_counts().head(10).plot(kind='bar', ax=axes[2])\n",
    "axes[2].set_title('Top 10 Subcategory Distribution')\n",
    "axes[2].set_ylabel('Count')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87849ba",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faddf12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xác định các cột cần encode\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "# Loại bỏ label columns khỏi categorical\n",
    "categorical_cols = [col for col in categorical_cols if col not in ['category', 'subcategory']]\n",
    "\n",
    "print(f\"Categorical columns cần encode: {categorical_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f529d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding cho categorical features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_dict = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    le_dict[col] = le\n",
    "    print(f\"Encoded {col}: {len(le.classes_)} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b22f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding cho target\n",
    "le_category = LabelEncoder()\n",
    "le_subcategory = LabelEncoder()\n",
    "\n",
    "df['category_encoded'] = le_category.fit_transform(df['category'])\n",
    "df['subcategory_encoded'] = le_subcategory.fit_transform(df['subcategory'])\n",
    "\n",
    "print(\"Category mapping:\")\n",
    "for i, cat in enumerate(le_category.classes_):\n",
    "    print(f\"  {i}: {cat}\")\n",
    "\n",
    "print(\"\\nSubcategory mapping:\")\n",
    "for i, subcat in enumerate(le_subcategory.classes_):\n",
    "    print(f\"  {i}: {subcat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bad62df",
   "metadata": {},
   "source": [
    "## 5. Save Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bcc025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu dataset đã xử lý\n",
    "output_path = Path(r'c:\\Users\\Tplab\\OneDrive\\CNN tutorial\\data\\processed')\n",
    "output_path.mkdir(exist_ok=True)\n",
    "\n",
    "output_file = output_path / 'bot_iot_processed.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Đã lưu dataset vào: {output_file}\")\n",
    "print(f\"File size: {output_file.stat().st_size / 1024**3:.2f} GB\")\n",
    "print(f\"Final shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cce47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu label encoders để dùng sau này\n",
    "import pickle\n",
    "\n",
    "encoders = {\n",
    "    'categorical': le_dict,\n",
    "    'category': le_category,\n",
    "    'subcategory': le_subcategory\n",
    "}\n",
    "\n",
    "with open(output_path / 'label_encoders.pkl', 'wb') as f:\n",
    "    pickle.dump(encoders, f)\n",
    "\n",
    "print(\"Đã lưu label encoders!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7211295",
   "metadata": {},
   "source": [
    "## 6. Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0435cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total samples: {len(df):,}\")\n",
    "print(f\"Total features: {df.shape[1]}\")\n",
    "print(f\"\\nAttack distribution:\")\n",
    "print(df['attack'].value_counts())\n",
    "print(f\"\\nMemory usage: {df.memory_usage(deep=True).sum() / 1024**3:.2f} GB\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442ff8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
